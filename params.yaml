dataset:
  cifar10:
    train_batch_size: 1024
    val_batch_size: 2048
    test_batch_size: 1000
    train_transforms: null
    test_transforms: null
    train_augm: null #${augmentation.train}
    test_augm: ${augmentation.val}
    val_size: 0.2
    download: False 
    random_state: 42
    num_workers: 4 

transforms:
  train:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.Resize
        size:
          - 32
          - 32
      - _target_: torchvision.transforms.RandomGrayscale
        p: 0.15
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 32
        scale:
          - 0.75
          - 1.0
        ratio: 
          - 1.0
          - 1.0
      - _target_: torchvision.transforms.RandomHorizontalFlip
        p: 0.5
      - _target_: torchvision.transforms.RandomRotation
        degrees: 20
      - _target_: torchvision.transforms.RandomAffine
        degrees: 15
        shear: 10
        scale:
          - 0.8
          - 1.2
      - _target_: torchvision.transforms.ColorJitter
        brightness: 0.2
        contrast: 0.2
        saturation: 0.2
      - _target_: torchvision.transforms.ToTensor
        #transforms.RandomApply([GaussianNoise(0.0, 0.1)], p=0.25),
        #torchvision.transforms.RandomApply([PepperNoise(amount=0.1)], p=0.8),
      - _target_: torchvision.transforms.Normalize
        mean:
          - 0.5
          - 0.5
          - 0.5
        std:
          - 0.5
          - 0.5
          - 0.5
  val:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.Resize
        size:
          - 32
          - 32
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean:
          - 0.5
          - 0.5
          - 0.5
        std:
          - 0.5
          - 0.5
          - 0.5


augmentation:
  train:
    _target_: albumentations.Compose
    transforms:
      - _target_: albumentations.OneOf
        transforms:
          - _target_: albumentations.RandomCrop
            height: 24
            width: 24
            # scale:
            #   - 0.75
            #   - 1.0
            # ratio:
            #   - 1
            #   - 1
            p: 0.5
          - _target_: albumentations.RandomCrop
            height: 16
            width: 16
            # scale:
            #   - 0.75
            #   - 1.0
            # ratio:
            #   - 1
            #   - 1
            p: 0.5
        p: 0.8 

      - _target_: albumentations.augmentations.geometric.resize.Resize
        height: 32
        width: 32

      - _target_: albumentations.OneOf
        transforms:
          - _target_: albumentations.CLAHE
            p: 0.25
          - _target_: albumentations.RandomBrightness
            p: 0.25
          - _target_: albumentations.RandomGamma
            p: 0.25
        p: 0.5

      - _target_: albumentations.OneOf
        transforms:
          - _target_: albumentations.IAASharpen
            p: 0.25
          - _target_: albumentations.Blur
            p: 0.25
          - _target_: albumentations.MotionBlur
            p: 0.25
        p: 0.5

      - _target_: albumentations.OneOf
        transforms:
          - _target_: albumentations.RandomContrast
            p: 1
          - _target_: albumentations.HueSaturationValue
            p: 1
        p: 0.5

      - _target_: albumentations.OneOf
        transforms:
          - _target_: albumentations.HorizontalFlip
            p: 1
          - _target_: albumentations.VerticalFlip
            p: 1
        p: 0.5

      - _target_: albumentations.augmentations.transforms.Normalize 
  val:
    _target_: albumentations.Compose
    transforms:
      - _target_: albumentations.augmentations.geometric.resize.Resize
        height: 32
        width: 32
      - _target_: albumentations.augmentations.transforms.Normalize 
criterion:
  criterion:
    _target_: torch.nn.CrossEntropyLoss
   # _partial_: True
model:
  model_type: torch_models
  net:
    _target_: torchvision.models.resnet18
    _partial_: True
  weights: None
  num_classes: 10

optimizer:
  optimizer:
    _target_: torch.optim.Adam
    _partial_: True
    lr: 0.001
scheduler:
  scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    _partial_: True
    gamma: 0.95
    #min_lr: 1e-6
    verbose: False
dataloaders:
  train_dataloader_kwargs:
    batch_size: 5
    num_workers: 32
  val_dataloader_kwargs:
    batch_size: 5
    num_workers: 32

metrics:
  accuracy_score:
    _target_: sklearn.metrics.accuracy_score
    _partial_: True
  recall_score:
    _target_: sklearn.metrics.recall_score
    _partial_: True
    average: weighted
  precision_score:
    _target_: sklearn.metrics.precision_score
    _partial_: True
    average: weighted

trainer:
  trainer_kwargs:
    accelerator: gpu
    devices: 1
    min_epochs: 300
    max_epochs: 400
    check_val_every_n_epoch: 1
    enable_model_summary: True
#     logger: ${logger.mlflow_logger}
# logger:
#   mlflow_logger:
#     _target_: pytorch_lightning.loggers.MLFlowLogger
#     experiment_name: mlflow_check
#     tracking_uri: ./ml-runs